import numpy as np
import tensorflow as tf
import os
import glob
import pandas as pd
import sys

# ê²½ë¡œ ì„¤ì •
ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

# ì‹œê°í™” ë„êµ¬ ì„í¬íŠ¸
from utils.viser_test import PoseViser

# -----------------------------------------------------------
# [ìˆ˜ì • 1] ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì •í™•íˆ ì§€ì • (.keras íŒŒì¼)
# -----------------------------------------------------------
MODEL_FILE_PATH = os.path.join(ROOT, "experiments", "height_mlp_model_2", "best_model.keras")

# ë°ì´í„° ê²½ë¡œ (ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ ë°ì´í„° ì‚¬ìš©)
PROCESSED_DIR = os.path.join(ROOT, "data", "processed", "test")
OUTPUT_DIR = os.path.join(ROOT, "data", "output")
os.makedirs(OUTPUT_DIR, exist_ok=True)

def load_trained_model():
    print(f"Loading model from: {MODEL_FILE_PATH}")
    if not os.path.exists(MODEL_FILE_PATH):
        raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”: {MODEL_FILE_PATH}")
    return tf.keras.models.load_model(MODEL_FILE_PATH)

def refine_sequence(model, pose_path, traj_path):
    # 1. ë°ì´í„° ë¡œë“œ (ì „ì²˜ë¦¬ëœ ë°ì´í„°)
    raw_pose = np.load(pose_path) # (T, 33, 3)
    raw_traj = np.load(traj_path) # (T, 4)
    
    T = raw_pose.shape[0]

    # 2. ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (Pose 99 + Trajectory 4 = 103ì°¨ì›)
    # ë§ˆì§€ë§‰ í”„ë ˆì„ì€ ì˜ˆì¸¡í•  'ë‹¤ìŒ'ì´ ì—†ìœ¼ë¯€ë¡œ ì œì™¸í•˜ê³  T-1ê°œë§Œ ì˜ˆì¸¡
    curr_pose = raw_pose[:-1].reshape(T-1, -1) # (T-1, 99)
    curr_traj = raw_traj[:-1]                  # (T-1, 4)
    
    # í•©ì¹˜ê¸° -> (Batch, 103)
    X = np.concatenate([curr_pose, curr_traj], axis=1)

    # 3. ì˜ˆì¸¡ (Inference)
    print(f"  > Predicting {T-1} frames...")
    pred_flat = model.predict(X, verbose=0) # (T-1, 99)
    
    # 4. í˜•íƒœ ë³µì› (T-1, 33, 3)
    pred_pose_3d = pred_flat.reshape(T-1, 33, 3)

    # 5. ê¸¸ì´ ë§ì¶”ê¸° (ë§ˆì§€ë§‰ í”„ë ˆì„ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ë¶™ì—¬ì„œ T ê¸¸ì´ ìœ ì§€)
    last_frame = raw_pose[-1].reshape(1, 33, 3)
    final_pose = np.concatenate([pred_pose_3d, last_frame], axis=0) # (T, 33, 3)

    return raw_pose, final_pose

def save_to_csv(data, filename):
    """
    (T, 33, 3) ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    ê¸°ëŠ¥: ë°œë°”ë‹¥ ì°©ì§€(Grounding) + ê²¹ì¹¨ ë°©ì§€(Widen) + ìœ ë‹ˆí‹° ìŠ¤ì¼€ì¼ ì¡°ì •
    """
    # ------------------------------------------------------------------
    # [1] ë°œë°”ë‹¥ ê¸°ì¤€ì  ì°¾ê¸° (ë…¸ì´ì¦ˆ ë¬´ì‹œí•˜ê³  ë°”ë‹¥ ì°©ì§€)
    # ------------------------------------------------------------------
    feet_indices = [29, 30, 31, 32] 
    all_feet_y = data[:, feet_indices, 1] 
    ground_level = np.percentile(all_feet_y, 1) # í•˜ìœ„ 1%ë¥¼ ë°”ë‹¥ìœ¼ë¡œ ê°„ì£¼
    
    # ë°”ë‹¥ìœ¼ë¡œ ë‚´ë¦¬ê¸°
    data[:, :, 1] -= ground_level

    # ------------------------------------------------------------------
    # [2] ìŠ¤ì¼€ì¼ ë° ê²¹ì¹¨ ë°©ì§€ ì„¤ì •
    # ------------------------------------------------------------------
    UNITY_SCALE = 0.55   # ì „ì²´ í¬ê¸°
    WIDTH_FACTOR = 1.2   # ì¢Œìš° ë²Œë¦¬ê¸° (ê²¹ì¹¨ ë°©ì§€)
    DEPTH_FACTOR = 1.3   # ì•ë’¤ ë²Œë¦¬ê¸° (ê²¹ì¹¨ ë°©ì§€)

    T, nBones, _ = data.shape
    rows = []
    
    for t in range(T):
        for b in range(nBones):
            x, y, z = data[t, b]
            
            # ìŠ¤ì¼€ì¼ ì ìš©
            x *= UNITY_SCALE
            y *= UNITY_SCALE
            z *= UNITY_SCALE
            
            # ë¼ˆëŒ€ ë²Œë¦¬ê¸°
            x *= WIDTH_FACTOR
            z *= DEPTH_FACTOR
            
            rows.append([t, b, x, y, z, 1.0])
    
    df = pd.DataFrame(rows, columns=["frame", "landmark", "x", "y", "z", "visibility"])
    save_path = os.path.join(OUTPUT_DIR, filename)
    df.to_csv(save_path, index=False)
    print(f"  -> CSV Saved: {save_path}")

def main():
    # 1. ëª¨ë¸ ë¡œë“œ
    try:
        model = load_trained_model()
    except Exception as e:
        print(e)
        return

    # 2. ë°ì´í„° ì°¾ê¸° (data/processed í´ë”ì—ì„œ)
    # ì›í•˜ëŠ” íŒŒì¼ë§Œ ì°¾ìœ¼ë ¤ë©´ ì•„ë˜ ê²€ìƒ‰ì–´ë¥¼ ìˆ˜ì •í•˜ì„¸ìš” (ì˜ˆ: "í˜„ì‹œê°")
    TARGET_KEYWORD = "" 
    
    all_files = glob.glob(os.path.join(PROCESSED_DIR, "*_pose.npy"))
    pose_files = [f for f in all_files if TARGET_KEYWORD in f]

    if not pose_files:
        print(f"âŒ '{PROCESSED_DIR}'ì—ì„œ í…ŒìŠ¤íŠ¸í•  ë°ì´í„°(_pose.npy)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë¨¼ì € '02_process_height_dataset.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
        return

    print(f"Found {len(pose_files)} sequences.")

    # 3. ë°˜ë³µ ì²˜ë¦¬
    for p_path in pose_files:
        t_path = p_path.replace("_pose.npy", "_trajectory.npy")
        
        # ê¶¤ì  íŒŒì¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ (ì§ì´ ë§ì•„ì•¼ í•¨)
        if not os.path.exists(t_path):
            print(f"âš ï¸ ê¶¤ì  íŒŒì¼ ì—†ìŒ (ìŠ¤í‚µ): {os.path.basename(t_path)}")
            continue

        base_name = os.path.basename(p_path).replace("_pose.npy", "")
        print(f"\nProcessing: {base_name}")

        # ì˜ˆì¸¡ ì‹¤í–‰
        raw_pose, refined_pose = refine_sequence(model, p_path, t_path)

        # ê²°ê³¼ ì €ì¥ (.npy)
        npy_out = os.path.join(OUTPUT_DIR, f"{base_name}_refined.npy")
        np.save(npy_out, refined_pose)

        # ê²°ê³¼ ì €ì¥ (.csv)
        save_to_csv(refined_pose, f"reconverted_{base_name}.csv")

        # 4. ì‹œê°í™” (Offset 1.0ìœ¼ë¡œ ë–¨ì–´ëœ¨ë ¤ì„œ ë³´ì—¬ì¤Œ)
        print("Displaying in PoseViser...")
        vis = PoseViser(fps=30)
        vis.play_two_sequences(raw_pose, refined_pose, offset=1.0)
        
        # í•˜ë‚˜ë§Œ ë³´ê³  ë©ˆì¶”ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
        # break 

if __name__ == "__main__":
    main()